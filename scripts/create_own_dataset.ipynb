{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ec884aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import yaml\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de21a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /home/max/Documents/GitHub/thesis/bop_toolkit/scripts/calc_gt_masks.py\n",
    "#!python /home/max/Documents/GitHub/thesis/bop_toolkit/scripts/calc_gt_info.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752713ef",
   "metadata": {},
   "source": [
    "## Create extra folders for every object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee5c24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/max/Documents/GitHub/thesis/output/bop_data/chess/train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000004', '000000', '000003', '000006', '000002', '000001', '000005']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "path = \"/home/max/Documents/GitHub/thesis/output/bop_data/chess/train/00000\"\n",
    "\n",
    "try:\n",
    "    folder_path = path + \"1\"\n",
    "    mask_path = path + \"1/mask\"\n",
    "    mask_visib_path = path + \"1/mask_visib\"\n",
    "    # Create the folders\n",
    "    os.mkdir(folder_path)\n",
    "    os.mkdir(mask_path)\n",
    "    os.mkdir(mask_visib_path)\n",
    "\n",
    "\n",
    "    folder_path = path + \"2\"\n",
    "    mask_path = path + \"2/mask\"\n",
    "    mask_visib_path = path + \"2/mask_visib\"\n",
    "    # Create the folders\n",
    "    os.mkdir(folder_path)\n",
    "    os.mkdir(mask_path)\n",
    "    os.mkdir(mask_visib_path)\n",
    "\n",
    "    folder_path = path + \"3\"\n",
    "    mask_path = path + \"3/mask\"\n",
    "    mask_visib_path = path + \"3/mask_visib\"\n",
    "    # Create the folders\n",
    "    os.mkdir(folder_path)\n",
    "    os.mkdir(mask_path)\n",
    "    os.mkdir(mask_visib_path)\n",
    "\n",
    "    folder_path = path + \"4\"\n",
    "    mask_path = path + \"4/mask\"\n",
    "    mask_visib_path = path + \"4/mask_visib\"\n",
    "    # Create the folders\n",
    "    os.mkdir(folder_path)\n",
    "    os.mkdir(mask_path)\n",
    "    os.mkdir(mask_visib_path)\n",
    "\n",
    "    folder_path = path + \"5\"\n",
    "    mask_path = path + \"5/mask\"\n",
    "    mask_visib_path = path + \"5/mask_visib\"\n",
    "    # Create the folders\n",
    "    os.mkdir(folder_path)\n",
    "    os.mkdir(mask_path)\n",
    "    os.mkdir(mask_visib_path)\n",
    "\n",
    "    folder_path = path + \"6\"\n",
    "    mask_path = path + \"6/mask\"\n",
    "    mask_visib_path = path + \"6/mask_visib\"\n",
    "    # Create the folders\n",
    "    os.mkdir(folder_path)\n",
    "    os.mkdir(mask_path)\n",
    "    os.mkdir(mask_visib_path)\n",
    "except:\n",
    "    print(\"directs already there\")\n",
    "\n",
    "current_dir = path.rstrip(\"/00000\")\n",
    "print(current_dir)\n",
    "directories = [d for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d))]\n",
    "\n",
    "directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e3e4b",
   "metadata": {},
   "source": [
    "## Change format to linemod preprocessed and change scene_gt with all objects to every gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2beb5a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 183692.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the original JSON data\n",
    "scene_gt_path = path + \"0/scene_gt.json\"\n",
    "with open(scene_gt_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Define the obj_ids for filtering\n",
    "obj_ids = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Filter the data for each obj_id\n",
    "filtered_data = {}\n",
    "for obj_id in tqdm(obj_ids):\n",
    "    filtered_data[obj_id] = {key: [item for item in items if item['obj_id'] == obj_id] for key, items in json_data.items()}\n",
    "    # Write the filtered_data dictionary to the output file as JSON\n",
    "    output_file = path + str(obj_id) + \"/scene_gt.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(filtered_data[obj_id], f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9fed9",
   "metadata": {},
   "source": [
    "## Give every folder the right masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73ab118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:57,  9.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask files copied successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:58,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask visible files copied successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 120.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_camera.json copied successfully.\n",
      "RGB Symbolic links created successfully.\n",
      "Depth Symbolic links created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "folder_path = path + \"0/mask\"\n",
    "\n",
    "# Get the list of all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Define the list of destination folders\n",
    "destination_folders = [\n",
    "    path + \"1/mask\",\n",
    "    path + \"2/mask\",\n",
    "    path + \"3/mask\",\n",
    "    path + \"4/mask\",\n",
    "    path + \"5/mask\",\n",
    "    path + \"6/mask\"\n",
    "]\n",
    "\n",
    "# Iterate over the destination folders\n",
    "for i, destination_folder in tqdm(enumerate(destination_folders, start=0)):\n",
    "    # Filter the files that end with \"{i}.png\"\n",
    "    image_files = [file for file in files if file.endswith(f\"{i}.png\")]\n",
    "    \n",
    "    # Copy the image files to the destination folder\n",
    "    for file in image_files:\n",
    "        source_file = os.path.join(folder_path, file)\n",
    "        destination_file = os.path.join(destination_folder, file)\n",
    "        shutil.copyfile(source_file, destination_file)\n",
    "        \n",
    "print(\"Mask files copied successfully.\")\n",
    "\n",
    "folder_path = path + \"0/mask_visib\" # Specify the folder path\n",
    "\n",
    "# Get the list of all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Define the list of destination folders\n",
    "destination_folders = [\n",
    "    path + \"1/mask_visib\",\n",
    "    path + \"2/mask_visib\",\n",
    "    path + \"3/mask_visib\",\n",
    "    path + \"4/mask_visib\",\n",
    "    path + \"5/mask_visib\",\n",
    "    path + \"6/mask_visib\"\n",
    "]\n",
    "\n",
    "# Iterate over the destination folders\n",
    "for i, destination_folder in tqdm(enumerate(destination_folders, start=0)):\n",
    "    # Filter the files that end with \"{i}.png\"\n",
    "    image_files = [file for file in files if file.endswith(f\"{i}.png\")]\n",
    "    \n",
    "    # Copy the image files to the destination folder\n",
    "    for file in image_files:\n",
    "        source_file = os.path.join(folder_path, file)\n",
    "        destination_file = os.path.join(destination_folder, file)\n",
    "        shutil.copyfile(source_file, destination_file)\n",
    "        \n",
    "print(\"Mask visible files copied successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "folder_path = path + \"0\" # Specify the folder path\n",
    "\n",
    "# Define the source file path\n",
    "source_file_path = os.path.join(folder_path, \"scene_camera.json\")\n",
    "\n",
    "# Define the list of destination folders\n",
    "destination_folders = [\n",
    "    path + \"1\",\n",
    "    path + \"2\",\n",
    "    path + \"3\",\n",
    "    path + \"4\",\n",
    "    path + \"5\",\n",
    "    path + \"6\"\n",
    "]\n",
    "\n",
    "# Iterate over the destination folders\n",
    "for i, destination_folder in tqdm(enumerate(destination_folders, start=1)):\n",
    "    # Define the destination file path\n",
    "    destination_file_path = os.path.join(destination_folder, \"scene_camera.json\")\n",
    "    \n",
    "    # Copy the source file to the destination folder\n",
    "    shutil.copyfile(source_file_path, destination_file_path)\n",
    "    \n",
    "print(\"scene_camera.json copied successfully.\")\n",
    "\n",
    "try:\n",
    "    # Specify the source directory\n",
    "    source_dir = path + \"0/rgb\" \n",
    "\n",
    "    # Create symbolic links for each destination folder\n",
    "    for folder in destination_folders:\n",
    "        destination_path = os.path.join(folder, \"rgb\")\n",
    "        os.symlink(source_dir, destination_path)\n",
    "        #print(f\"Symbolic link created from {source_dir} to {destination_path}\")\n",
    "\n",
    "    print(\"RGB Symbolic links created successfully.\")\n",
    "except: \n",
    "    print(\"something wrong with symbolic links rgb\")\n",
    "    \n",
    "try:\n",
    "    # Specify the source directory\n",
    "    source_dir = path + \"0/depth\" \n",
    "\n",
    "    # Create symbolic links for each destination folder\n",
    "    for folder in destination_folders:\n",
    "        destination_path = os.path.join(folder, \"depth\")\n",
    "        os.symlink(source_dir, destination_path)\n",
    "        #print(f\"Symbolic link created from {source_dir} to {destination_path}\")\n",
    "\n",
    "    print(\"Depth Symbolic links created successfully.\")\n",
    "except: \n",
    "    print(\"something wrong with symbolic links depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e72fc",
   "metadata": {},
   "source": [
    "### Create scene_gt_info for every object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89c7dae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = path + \"0\" # Specify the folder path\n",
    "\n",
    "# Define the source file path\n",
    "source_file_path = os.path.join(folder_path, \"scene_gt_info.json\")\n",
    "\n",
    "with open(source_file_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "# Define the list of destination folders\n",
    "destination_folders = [\n",
    "    path + \"1\",\n",
    "    path + \"2\",\n",
    "    path + \"3\",\n",
    "    path + \"4\",\n",
    "    path + \"5\",\n",
    "    path + \"6\"\n",
    "]\n",
    "\n",
    "for i, destination_folder in tqdm(enumerate(destination_folders, start=1)):\n",
    "    # Define the destination file path\n",
    "    first_dicts = {}\n",
    "    for key, data_list in json_data.items():\n",
    "        #if len(data_list) > 0:\n",
    "            # Keep only the first dictionary\n",
    "        first_dict = data_list[i-1]\n",
    "        first_dicts[str(key)] = [first_dict]\n",
    "    # Save the first dictionaries in a single JSON file\n",
    "    destination_file_path = destination_folders[i-1] + \"/scene_gt_info.json\"\n",
    "\n",
    "    #with open(destination_file_path, 'w') as json_file:\n",
    "    #    json.dump(first_dicts, json_file)\n",
    "\n",
    "    with open(destination_file_path, 'w') as json_file:\n",
    "        json_file.write(\"{\\n\")\n",
    "        for i, (key, value) in enumerate(first_dicts.items()):\n",
    "            json_file.write(f'    \"{key}\": {json.dumps(value)}')\n",
    "            if i < len(first_dicts) - 1:\n",
    "                json_file.write(\",\\n\")\n",
    "            else:\n",
    "                json_file.write(\"\\n\")\n",
    "        json_file.write(\"}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56aa7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /home/max/Documents/GitHub/thesis/bop_toolkit/scripts/calc_gt_info.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59309c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06', '03', '05', '02', '01', '04']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    base_path = \"/home/max/Documents/GitHub/thesis/output/bop_data/chess/\"\n",
    "    folders = [base_path + 'train/' + f\"{i:06d}\" for i in range(1, 7)]\n",
    "    new_folders = [base_path +'data/'+ f\"{i:02d}\" for i in range(1, 7)]\n",
    "\n",
    "    for folder, new_folder in tqdm(zip(folders, new_folders)):\n",
    "        contents = os.listdir(folder)\n",
    "\n",
    "        # Filter out \"rgb\" and \"depth\" directories\n",
    "        filtered_contents = [item for item in contents if item not in [\"rgb\", \"depth\"]]\n",
    "\n",
    "        for item in filtered_contents:\n",
    "            source = os.path.join(folder, item)\n",
    "            destination = os.path.join(new_folder, item)\n",
    "\n",
    "            if os.path.isdir(source):\n",
    "                shutil.copytree(source, destination)\n",
    "            else:\n",
    "                shutil.copy(source, destination)\n",
    "        shutil.rmtree(folder)\n",
    "                \n",
    "except:\n",
    "    print(\"already moved\")\n",
    "\n",
    "current_dir = \"/home/max/Documents/GitHub/thesis/output/bop_data/chess/data\"\n",
    "directories = [d for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d))]\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0edba725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something wrong with symbolic links rgb\n",
      "Depth Symbolic links created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the list of destination folders\n",
    "path_data = \"/home/max/Documents/GitHub/thesis/output/bop_data/chess/data/0\"\n",
    "destination_folders = [\n",
    "    path_data + \"1\",\n",
    "    path_data + \"2\",\n",
    "    path_data + \"3\",\n",
    "    path_data + \"4\",\n",
    "    path_data + \"5\",\n",
    "    path_data + \"6\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Specify the source directory\n",
    "    source_dir = path_data + \"1/rgb\" \n",
    "    # Create symbolic links for each destination folder\n",
    "    i = 0\n",
    "    for folder in destination_folders:\n",
    "        if i == 0:\n",
    "            i = i+1\n",
    "        else:\n",
    "            destination_path = os.path.join(folder, \"rgb\")\n",
    "            os.symlink(source_dir, destination_path)\n",
    "            #print(f\"Symbolic link created from {source_dir} to {destination_path}\")\n",
    "\n",
    "    print(\"RGB Symbolic links created successfully.\")\n",
    "except: \n",
    "    print(\"something wrong with symbolic links rgb\")\n",
    "    \n",
    "try:\n",
    "    # Specify the source directory\n",
    "    source_dir = path_data + \"1/depth\" \n",
    "\n",
    "    # Create symbolic links for each destination folder\n",
    "    i = 0\n",
    "    \n",
    "    for folder in destination_folders:\n",
    "        if i == 0:\n",
    "            i=i+1\n",
    "        else:\n",
    "            destination_path = os.path.join(folder, \"depth\")\n",
    "            os.symlink(source_dir, destination_path)\n",
    "            #print(f\"Symbolic link created from {source_dir} to {destination_path}\")\n",
    "\n",
    "    print(\"Depth Symbolic links created successfully.\")\n",
    "except: \n",
    "    print(\"something wrong with symbolic links depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a6a87",
   "metadata": {},
   "source": [
    "## Create gt.yml & info.yml files from scene_gt.json and scene_gt_info.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ca2acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [06:56<00:00, 69.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for directory in tqdm(directories):\n",
    "    json_file_dataset = current_dir + \"/\" + directory + \"/scene_gt.json\"\n",
    "    json_file_bbox = current_dir + \"/\" + directory + \"/scene_gt_info.json\"\n",
    "\n",
    "    output_file = current_dir + \"/\" + directory + \"/gt.yml\"\n",
    "    # Open the JSON file and load its contents as a dictionary\n",
    "    with open(json_file_dataset, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        \n",
    "    with open(json_file_bbox, 'r') as json_file:\n",
    "        json_data_bbox = json.load(json_file)\n",
    "        \n",
    "    # Convert to YAML string\n",
    "    yaml_str = ''\n",
    "    for k, v in json_data.items():\n",
    "        yaml_str += f\"{k}: \\n\"\n",
    "        yaml_str += f\"- cam_R_m2c: {v[0]['cam_R_m2c']}\\n\"\n",
    "        yaml_str += f\"  cam_t_m2c: {v[0]['cam_t_m2c']}\\n\"\n",
    "        yaml_str += f\"  obj_bb: {json_data_bbox[str(k)][0]['bbox_obj']}\\n\"\n",
    "        yaml_str += f\"  obj_id: {v[0]['obj_id']}\\n\"\n",
    "\n",
    "    \n",
    "    # Convert the dictionary to YAML format\n",
    "    yaml_data = yaml.dump(json_data, default_flow_style=False)\n",
    "\n",
    "    # Write the YAML data to a file\n",
    "    with open(output_file, 'w') as yaml_file:\n",
    "        yaml_file.write(yaml_str)\n",
    "        \n",
    "    json_file_info = current_dir + \"/\" + directory + \"/scene_camera.json\"\n",
    "    with open(json_file_info, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    yaml_str = ''\n",
    "    for k, v in json_data.items():\n",
    "        yaml_str += f\"{k}: \\n\"\n",
    "        yaml_str += f\" cam_K: {v['cam_K']}\\n\"\n",
    "        yaml_str += f\" depth_scale: {v['depth_scale']}\\n\"\n",
    "\n",
    "    yaml_data = yaml.dump(json_data, default_flow_style=False)\n",
    "    \n",
    "    info_file = current_dir + \"/\" + directory + \"/info.yml\"\n",
    "    # Write the YAML data to a file\n",
    "    with open(info_file, 'w') as yaml_file:\n",
    "        yaml_file.write(yaml_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f36c7",
   "metadata": {},
   "source": [
    "### Rename images to efficientpose like images and create train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9645ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visib_fract_threshold = 0.3 #30% needs to be visible for the test or train dataset\n",
    "\n",
    "for directory in directories:\n",
    "    direc_rgb = current_dir + \"/\" + directory + \"/rgb\"\n",
    "    direc_depth = current_dir + \"/\" + directory + \"/depth\"\n",
    "    direc_mask = current_dir + \"/\" + directory + \"/mask\"\n",
    "    direc_mask_visib = current_dir + \"/\" + directory + \"/mask_visib\"\n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(direc_mask):\n",
    "        if len(filename) == 17:\n",
    "            # Get the first 6 characters of the filename\n",
    "            new_filename = filename[1:6] + \".png\"\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(direc_mask, filename), os.path.join(direc_mask, new_filename))\n",
    "        \n",
    "        else: \n",
    "            break\n",
    "\n",
    "    for filename in os.listdir(direc_mask_visib):\n",
    "        if len(filename) == 17:\n",
    "            # Get the first 6 characters of the filename\n",
    "            new_filename = filename[1:6] + \".png\"\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(direc_mask_visib, filename), os.path.join(direc_mask_visib, new_filename))\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    for filename in os.listdir(direc_rgb):\n",
    "        if len(filename) == 10:\n",
    "            # Get the first 6 characters of the filename\n",
    "            new_filename = filename[1:]\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(direc_rgb, filename), os.path.join(direc_rgb, new_filename))\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    for filename in os.listdir(direc_depth):\n",
    "        if len(filename) == 10:\n",
    "            # Get the first 6 characters of the filename\n",
    "            new_filename = filename[1:]\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(direc_depth, filename), os.path.join(direc_depth, new_filename))\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "    # Open the JSON file and load its contents as a dictionary\n",
    "    output_file = current_dir + \"/\" + directory + \"/scene_gt_info.json\"\n",
    "        \n",
    "    with open(output_file, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        \n",
    "    all_images_threshold = []\n",
    "    for key, value in json_data.items():\n",
    "        for i, v in enumerate(value):\n",
    "            if v['visib_fract'] > visib_fract_threshold:\n",
    "                image_threshold = '{:04d}'.format(int(key))\n",
    "                all_images_threshold.append(image_threshold)\n",
    "        \n",
    "    train_list, test_list = train_test_split(all_images_threshold, test_size=0.03, random_state=42)\n",
    "    \n",
    "    converted_numbers_train = []\n",
    "\n",
    "    for number in train_list:\n",
    "        converted_number = number.zfill(5)\n",
    "        converted_numbers_train.append(converted_number)\n",
    "        \n",
    "    converted_numbers_test = []\n",
    "\n",
    "    for number in test_list:\n",
    "        converted_number = number.zfill(5)\n",
    "        converted_numbers_test.append(converted_number)\n",
    "    \n",
    "    #train file\n",
    "    filename = \"train.txt\"\n",
    "    folder =  current_dir + \"/\" + directory\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write('\\n'.join(converted_numbers_train))\n",
    "        \n",
    "    #Test file\n",
    "    filename = \"test.txt\"\n",
    "    folder =  current_dir + \"/\" + directory\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write('\\n'.join(converted_numbers_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87aaa476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 61909/61909 [1:33:48<00:00, 11.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "folder_path = '/home/max/Documents/GitHub/thesis/output/bop_data/chess/train/000000/rgb'  # Replace with the actual folder path\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        # Open the image file\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Convert and save the image as PNG\n",
    "        new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "        new_image_path = os.path.join(folder_path, new_filename)\n",
    "        image.save(new_image_path, 'PNG')\n",
    "        os.remove(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ddf3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "\n",
    "# Read the JSON file\n",
    "with open('/home/max/Documents/GitHub/thesis/output/bop_data/chess/models/models_info.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Convert dictionary keys to strings and format the output\n",
    "data_dict = {int(key): {k: round(v, 8) if isinstance(v, float) else v for k, v in value.items()} for key, value in data.items()}\n",
    "\n",
    "# Write the YAML file\n",
    "with open('output.yml', 'w') as yaml_file:\n",
    "    yaml.dump(data_dict, yaml_file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "153f4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56219\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/max/Documents/GitHub/thesis/output/bop_data/lm/train_pbr/000000/scene_camera.json') as yml_file:\n",
    "    json_data = json.load(yml_file)\n",
    "\n",
    "print(len(json_data))\n",
    "if len(json_data) > 60000:\n",
    "    print(\"hoi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51f80ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27305\n",
      "35899\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "# Read the YAML file\n",
    "with open('/home/max/Documents/GitHub/thesis/output/bop_data/lm/train_pbr/000000/scene_camera.json') as yml_file:\n",
    "    json_data = json.load(yml_file)\n",
    "\n",
    "visib_fract_threshold = 0.3\n",
    "j = 0\n",
    "for key, value in json_data.items():\n",
    "    for i, v in enumerate(value):\n",
    "        if v['visib_fract'] > visib_fract_threshold:\n",
    "            j = j+1\n",
    "            \n",
    "print(j)\n",
    "print(len(json_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856f86d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import yaml\\nimport numpy as np\\nfrom scipy.spatial.transform import Rotation\\n\\n# Read the YAML file\\nwith open(\\'/home/max/Documents/GitHub/thesis/output/bop_data/chess/data/02/gt.yml\\') as yml_file:\\n    data = yaml.load(yml_file, Loader=yaml.SafeLoader)\\n\\nyaml_str = \\'\\'\\n# Iterate over the data and update the rotation matrices\\nfor entry in data:\\n    #for item in data[entry]:\\n    item = data[entry]\\n    rotation_matrix = np.array(data[entry][0][\\'cam_R_m2c\\']).reshape(3, 3)\\n    # Convert the rotation matrix to axis-angle representation\\n    r = Rotation.from_matrix(rotation_matrix)\\n    axis_angle = r.as_rotvec()\\n\\n    # Convert the axis-angle representation to a list\\n    axis_angle_list = axis_angle.tolist()\\n\\n    # Update the rotation matrix with the axis-angle representation\\n    data[entry][0][\\'cam_R_m2c\\'] = axis_angle_list\\n\\n    yaml_str += f\"{entry}: \\n\"\\n    yaml_str += f\"- cam_R_m2c: {data[entry][0][\\'cam_R_m2c\\']}\\n\"\\n    yaml_str += f\"  cam_t_m2c: {data[entry][0][\\'cam_t_m2c\\']}\\n\"\\n    yaml_str += f\"  obj_bb: {data[entry][0][\\'obj_bb\\']}\\n\"\\n    yaml_str += f\"  obj_id: {data[entry][0][\\'obj_id\\']}\\n\"\\n\\n    # Print or use the yaml_str as needed\\n\\nprint(yaml_str)\\nyaml_data = yaml.dump(json_data, default_flow_style=False)\\n\\n# Write the modified YAML data back to the file\\nwith open(\\'/home/max/Documents/GitHub/thesis/output/bop_data/chess/data/02/gt_2.yml\\', \\'w\\') as yml_file:\\n    yml_file.write(yaml_str)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import yaml\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# Read the YAML file\n",
    "with open('/home/max/Documents/GitHub/thesis/output/bop_data/chess/data/02/gt.yml') as yml_file:\n",
    "    data = yaml.load(yml_file, Loader=yaml.SafeLoader)\n",
    "\n",
    "yaml_str = ''\n",
    "# Iterate over the data and update the rotation matrices\n",
    "for entry in data:\n",
    "    #for item in data[entry]:\n",
    "    item = data[entry]\n",
    "    rotation_matrix = np.array(data[entry][0]['cam_R_m2c']).reshape(3, 3)\n",
    "    # Convert the rotation matrix to axis-angle representation\n",
    "    r = Rotation.from_matrix(rotation_matrix)\n",
    "    axis_angle = r.as_rotvec()\n",
    "\n",
    "    # Convert the axis-angle representation to a list\n",
    "    axis_angle_list = axis_angle.tolist()\n",
    "\n",
    "    # Update the rotation matrix with the axis-angle representation\n",
    "    data[entry][0]['cam_R_m2c'] = axis_angle_list\n",
    "\n",
    "    yaml_str += f\"{entry}: \\n\"\n",
    "    yaml_str += f\"- cam_R_m2c: {data[entry][0]['cam_R_m2c']}\\n\"\n",
    "    yaml_str += f\"  cam_t_m2c: {data[entry][0]['cam_t_m2c']}\\n\"\n",
    "    yaml_str += f\"  obj_bb: {data[entry][0]['obj_bb']}\\n\"\n",
    "    yaml_str += f\"  obj_id: {data[entry][0]['obj_id']}\\n\"\n",
    "\n",
    "    # Print or use the yaml_str as needed\n",
    "\n",
    "print(yaml_str)\n",
    "yaml_data = yaml.dump(json_data, default_flow_style=False)\n",
    "\n",
    "# Write the modified YAML data back to the file\n",
    "with open('/home/max/Documents/GitHub/thesis/output/bop_data/chess/data/02/gt_2.yml', 'w') as yml_file:\n",
    "    yml_file.write(yaml_str)\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6a2b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65687c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
